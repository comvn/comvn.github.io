---
layout:     post
title:      The system design - Cache
subtitle:   The cache is a layer that stores a subset of data, typically the most frequently accessed or essential information, in a location quicker to access than its primary storage location. This caching strategy is used to reduce latency and improve the efficiency of data retrieval across the distributed system.
date:       2024-01-31
author:     NDA
header-img: img/post-bg-ios9-web.jpg
catalog:    true
tags:
    - System Design
    - Cache
---

>The cache is a layer that stores a subset of data, typically the most frequently accessed or essential information, in a location quicker to access than its primary storage location. This caching strategy is used to reduce latency and improve the efficiency of data retrieval across the distributed system. https://hackernoon.com/the-system-design-cheat-sheet-cache

Terms of Caching
-----

* **Cache Hit**: Occurs when the requested data is found in the cache, allowing for faster data retrieval.
* **Cache Miss**: This happens when the requested data is not in the cache, necessitating fetching the data from its primary storage location.
* **Cache Eviction**: The process of removing data from the cache, typically to make space for new data.
* **Cache Staleness**: Refers to the situation where the data in the cache is outdated compared to the data in the primary storage.
* **Cache Warm-Up**: The process of preloading the cache with data before it is actively used to avoid cache misses in the early stages of usage.
* **Cache State**: The status of data stored in a cache:
    * **Hot**: Cache contains data that is being accessed very frequently and recently.
    * **Warm**: Cache is not as actively used as a hot cache but still contains relatively frequently accessed data.
    * **Cold**: Cache is first initialized and has not yet had any data loaded.

Benefits of using Caching
-----

* **Reduced Latency**: Caching significantly decreases the time it takes to access data, leading to faster response times for user requests.
* **Decreased Network Traffic**: By storing frequently accessed data locally, caching reduces the amount of data that must be transmitted over a network, thereby decreasing network congestion.
* **Lower Load on Primary Data Stores**: Caching reduces the number of queries to primary data sources like databases, decreasing their load and potentially increasing lifespan.
* **Improved Performance**: Applications and systems often experience a general performance boost, as retrieving data from a cache is typically faster than accessing it from primary storage.
* **Increased Throughput**: Systems can handle more data and user requests in a given time due to the efficiency gains from caching.
* **Data Availability**: In some caching strategies, data can still be available even if the primary data source is temporarily unavailable.

Challenges of using Caching
-----

* **Cache Coherence**: Ensuring that data remains consistent across multiple caches in a distributed system.
* **Cache Invalidation**: Deciding when and how to update or remove data in the cache, especially when the original data changes.
* **Stale Data**: Handling scenarios where data in the cache is outdated compared to the primary data source.
* **Cache Sizing**: Determining the optimal size of the cache to balance performance gains with resource usage.
* **Cache Eviction Policies**: Choosing appropriate algorithms for which data to keep in the cache and which to evict when the cache is full.
* **Data Locality**: Ensuring data is stored in a cache close to where it is most frequently accessed to minimize latency.
* **Scalability**: Ensuring the cache can scale as the amount of data and the number of users increase.
* **Warm-up Time**: Managing the time for a cache to “warm up” and become effective after being cleared or created.
* **Thundering Herd Problem**: This occurs when a cached item expires, and multiple clients or processes simultaneously attempt to regenerate the same cache item, causing a surge in load on the data store or compute resources.
* **Cache Penetration**: This happens when queries for non-existent data (not in cache or primary storage) repeatedly bypass the cache and hit the database, potentially leading to performance degradation.
* **Big Key Problem**: Arises when a single cache key is associated with a large amount of data, leading to inefficiencies in cache utilization and potential performance issues.
* **Hot Key Challenge**: Refers to a situation where a few keys are accessed much more frequently than others, causing load imbalances and potential bottlenecks in the caching system.

Types of Caching
------


![](https://hackernoon.imgix.net/images/iOvSeC4bWUctj2q3XImABGDqXVO2-rl83dcd.jpeg)